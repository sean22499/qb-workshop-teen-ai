{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teen in Machine Learning Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science Goal\n",
    "\n",
    "> **Now imagine you are a data scientist working at QuantumBlack. \n",
    "> One day you have a new client, a pharmaceutical company trying to develop a new drug in the market for heart disease. From the feedback in one of the client meetings, the first step to approach this problem is to find the cause of heart disease.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Problem\n",
    "Of all the applications of machine-learning, diagnosing any serious disease using a black box is always going to be a hard sell. If the output from a model is the particular course of treatment (potentially with side-effects), or surgery, or the absence of treatment, people are going to want to know why.\n",
    "\n",
    "This dataset gives a number of variables along with a target condition of having or not having heart disease. Below, the data is first used in a simple random forest model, and then the model is investigated using ML explainability tools and techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive analytics\n",
    "\n",
    "Descriptive analytics is one of the most critical stages within any analytics project. Although projects can vary quite significantly, this phase typically lasts 2-3 weeks and should allow us to answer the following questions:  \n",
    "\n",
    "* Do I have the data required to make actionable recommendations at the end of the project?\n",
    "* Are there any underlying issues with the data such as missing values or data errors?\n",
    "* What has happened in the past and why?\n",
    "* Does the data make business sense and align with previous results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "#### Importing packages\n",
    "Packages allow us to do more complex operations, here are some descriptions of what packages are used throughout this excercise:  \n",
    "\n",
    "* `pandas`     : This allows us to do data manipulation\n",
    "* `matplotlib` : A packages that allows us to interactively visualise and plot data\n",
    "* `seaborn`    : This interacts well with matplotlib and gives diagrams more visually appealing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from subprocess import call\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "from sklearn.ensemble import RandomForestClassifier  #for the model\n",
    "from sklearn.metrics import auc, roc_curve  # for model evaluation\n",
    "from sklearn.metrics import confusion_matrix  #for model evaluation\n",
    "from sklearn.model_selection import train_test_split  #for data splitting\n",
    "from sklearn.tree import export_graphviz  #plot tree\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a big picture of dataset\n",
    "There are few functions that are useful to get a big picture of dataset \n",
    "\n",
    "* `df.head()`: Print first n (default=5) rows of dataset\n",
    "* `df.info()`: Give overall information of dataset like column names, non-null row count and data type in one go\n",
    "* `df['categorical_column_name'].value_counts()`: Count distinct value (**For Categorical Columns**)\n",
    "* `df.describe()`: Basic statistics (count, max, min, quantiles) (**For Numerical Columns**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data from the data folder\n",
    "df_raw = pd.read_csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets check the feed data and scan through the structure\n",
    "\"\"\"\n",
    "Hint : You can use .head(x) to look at the top x rows of data\n",
    "\"\"\"\n",
    "df_raw.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A good way to get the bigger picture of the dataset is to use .info()\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **When reading the dataset, you realise the meaning of some column names are not very obvious, so you talked to your client to ask them to clarify. Here is what they said:**\n",
    "\n",
    "* age: The person's age in years\n",
    "* sex: The person's sex (1 = male, 0 = female)\n",
    "* cp: The chest pain experienced (Value 1: typical angina, Value 2: atypical angina, Value 3: non-anginal pain, Value 4: asymptomatic)\n",
    "* trestbps: The person's resting blood pressure (mm Hg on admission to the hospital)\n",
    "* chol: The person's cholesterol measurement in mg/dl\n",
    "* fbs: The person's fasting blood sugar (> 120 mg/dl, 1 = true; 0 = false)\n",
    "* restecg: Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria)\n",
    "* thalach: The person's maximum heart rate achieved\n",
    "* exang: Exercise induced angina (1 = yes; 0 = no)\n",
    "* oldpeak: ST depression induced by exercise relative to rest ('ST' relates to positions on the ECG plot. See more here)\n",
    "* slope: the slope of the peak exercise ST segment (Value 1: upsloping, Value 2: flat, Value 3: downsloping)\n",
    "* ca: The number of major vessels (0-3)\n",
    "* thal: A blood disorder called thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)\n",
    "* target: Heart disease (0 = no, 1 = yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# descriptive summary of numerical columns\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect data quality\n",
    "1. 1st Thing: Eye-ball if **data type** is correct\n",
    ">1. It is common that some columns are in wrong data type \n",
    ">1. (e.g., data type for age can be numerical)\n",
    ">1. can use `pd.to_numeric(df)` or `df.astype()` to change data type accordingly\n",
    "\n",
    "1. 2nd Thing: There ususally some numerical columns required fixing (e.g., use commas for large values)\n",
    "> `mining[fix_cols] = mining[fix_cols] \\\n",
    "    .apply(lambda x : x.str.replace(\",\",\".\")) \\\n",
    "    .apply(pd.to_numeric)`\n",
    "\n",
    "1. 3rd Thing: Pay attention to null values\n",
    "> 1. remove null rows/columns `dropna()`\n",
    "> 1. impute null with median/mean `fillna()`\n",
    "\n",
    "> **In our case, our data is very clean, so we can proceed to next step of analysis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning data into insights\n",
    "Data visualisation is vital for insights before modelling step. The following plots are commonly used for gaining insights.\n",
    "\n",
    "1. `histogram`\n",
    "> A histogram is an accurate representation of the distribution of numerical data. It is an estimate of the probability distribution of a continuous variable (CORAL).\n",
    "\n",
    "1. `box plot`\n",
    "> The box plot (a.k.a. box and whisker diagram) is a standardized way of displaying the distribution of data based on the five number summary: minimum, first quartile, median, third quartile, and maximum. It is an important plot for descriptive statistics.\n",
    "\n",
    "1. `correlation plot`/`clustermap (using hierarchical clusering)`\n",
    "> A correlation matrix is a table showing correlation coefficients between variables. Each cell in the table shows the correlation between two variables. A clustermap is a correlation matrix with hierarchical clustering.\n",
    "\n",
    "1. `scatter plot`\n",
    "> A scatterplot displays a relationship between two sets of data. A scatterplot can also be called a scattergram or a scatter diagram. Scatter plots show how much one variable is affected by another. It is another way to demonstrate correlation between two variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_raw.hist(bins=15, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_raw.boxplot(column=['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "corr = df_raw.corr()\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the figure and its dimensions\n",
    "f, ax = plt.subplots(figsize=(50, 30))\n",
    "\n",
    "# Generate a colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the correlation matrix with the colormap above\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up the figure and its dimensions\n",
    "# f, ax = plt.subplots(figsize=(50, 30))\n",
    "# Draw the correlation matrix with the colormap above\n",
    "sns.clustermap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df_raw, hue='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive modelling\n",
    "The predictive analysis follows a descriptive stage, once we have:\n",
    " - cleaned the data\n",
    " - created a few derived variables\n",
    " - have a better understanding of the data. \n",
    " \n",
    "Its aim is to build a performing predictive model and identify the main drivers. This is an iterative process as a variety of modelling approaches and features are tried and tested.\n",
    "\n",
    "> **In general, modelling can be characterised into** \n",
    "> 1. **classification problem** (discrete target)\n",
    "> 1. **regression problem** (continuous target)\n",
    "\n",
    "> **Here, as the target is whether or not a patient will get heart disease, it is a CLASSIFICATION problem.**\n",
    "\n",
    "### The Bias - Variance tradeoff\n",
    "\n",
    "A good prediction model is evaluated against 3 main criteria - it must be:\n",
    "1. Simple\n",
    "2. Robust\n",
    "3. Performant\n",
    "\n",
    "If you make your model very complex, so that it fits the train data very accurately, it will not be able to model new data accurately - this is what we call **overfitting** (cf. image here below).\n",
    "On the other hand, if it is too simple, it will not be able to model the data very accurately - this is what we call **underfitting** (cf. image here below).\n",
    "\n",
    "![](images/overfitting.png)\n",
    "Source: https://en.wikipedia.org/wiki/File:Overfitting.svg\n",
    "\n",
    "We need to find a tradeoff between a model's complexity and its predicting performance. \n",
    "In the following image, we can see that the best tradeoff is where the arrow is pointing.\n",
    "\n",
    "\n",
    "![](images/overfitting_v2.png)\n",
    "\n",
    "Source: https://en.wikipedia.org/wiki/File:Overfitting_svg.svg\n",
    "\n",
    "## You can't have it all\n",
    "\n",
    "> If the algorithm we select is simple, explainable and interpretable, this may help the experts trust and leverage this tool a lot more. However I understand a complex algorithm may yield greater benefits and I would like to understand that tradeoff between complexity and benefit a bit better.\n",
    "\n",
    "After that meeting you set out to do the following : \n",
    "* Build a collection of both simple and complex models to understand the trade-off between complexity and benefits\n",
    "* Show diagrams of how the models work in a simplistic manner by exposing components of the model\n",
    "* Generate feature importance for each model so that the main drivers can be better exposed and trusted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / test split\n",
    "Train / test split\n",
    "A good prediction model must be generalisable - i.e., it should be able to make accurate predictions on new data. Several methods exists, to make our model more generalisable, of which the 'train/test split'.\n",
    "\n",
    "* **Train Set**: The training set contains a known output and the model learns on this data in order to be generalized to other data later on\n",
    "* **Test Set**: We have the test dataset (or subset) in order to test our model’s prediction on this subset.\n",
    "\n",
    "Other methods, such as train/test/validation split and cross-validation take this approach one step further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_raw.drop('target', 1), \n",
    "                                                    df_raw['target'], \n",
    "                                                    test_size = .2, \n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model - Random Forest\n",
    "\n",
    "The random forest is a model **made up of many decision trees**. Rather than just simply averaging the prediction of trees (which we could call a “forest”), this model uses two key concepts that gives it the name random:\n",
    "\n",
    "1. Random **sampling of training data points** when building trees\n",
    "1. Random **subsets of features** considered when splitting nodes\n",
    "\n",
    "###### Decision tree\n",
    "\n",
    "A decision tree can be perceived as a set of rules which enable to better describe and predict a given phenomenon, e.g., here, the yes/no heart disease. As its name indicates, a tree is composed of branches (which link the nodes to one another or to the final leaves), nodes (in the middle of the tree) and leaves (higher end of the tree).\n",
    "\n",
    "In our case, the tree splits at each node, on a **rule/condition** (explanatory variable and a set of values) according to a criterion (Gini), to better separate Low vs High populations.\n",
    "\n",
    "The decision tree algorithm has several important hyperparameters (cf. advanced section to know more). Understanding these will enable you to avoir overfitting:\n",
    "\n",
    "* the splitting criterion, for each node: Gini (most frequently used), entropy etc.\n",
    "* the maximum depth of the tree: how many branches link the first node to the end leaves?\n",
    "* the minimum sample split: the minimum number of data points in each node, after a split\n",
    "* the minimum samples per leaf: the minimum number of data points in each final leaf\n",
    "* the maximum number of features to consider when looking for the best split *(from the sklearn documentation)*:\n",
    "    * If int, then consider max_features features at each split.\n",
    "    * If float, then max_features is a percentage and int(max_features * n_features) features are considered at each split.\n",
    "    * If “auto”, then max_features=sqrt(n_features).\n",
    "    * If “sqrt”, then max_features=sqrt(n_features).\n",
    "    * If “log2”, then max_features=log2(n_features).\n",
    "    * If None, then max_features=n_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(max_depth=5, n_estimators=10)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "y_pred_quant = model.predict_proba(X_test)[:, 1]\n",
    "y_pred_bin = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = model.estimators_[1]\n",
    "feature_names = [i for i in X_train.columns]\n",
    "\n",
    "y_train_str = y_train.astype('str')\n",
    "y_train_str[y_train_str == '0'] = 'no disease'\n",
    "y_train_str[y_train_str == '1'] = 'disease'\n",
    "y_train_str = y_train_str.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = feature_names,\n",
    "                class_names = y_train_str,\n",
    "                rounded = True, proportion = True, \n",
    "                label='root',\n",
    "                precision = 2, filled = True)\n",
    "\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "\n",
    "Image(filename = 'tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Feature Importance\n",
    "\n",
    "The feature importances in a random forest indicate the sum of the reduction in Gini Impurity over all the nodes that are split on that feature. We can use these to try and figure out what predictor variables the random forest considers most important.\n",
    "\n",
    "> **Gini Impurity**:\n",
    "> The Gini Impurity represents the probability that a randomly selected sample from the node will be incorrectly classified according to the distribution of samples in the node. At the top, there is a 44.4% chance that a randomly selected point would be incorrectly classified. The Gini Impurity is how the decision tree makes splits. It splits the samples based on the value of a feature that reduces the Gini Impurity by the largest amount. If we do the math, the average (weighted by number of samples) Gini Impurity decreases as we move down the tree.\n",
    "\n",
    "> Eventually, the average Gini Impurity goes to 0.0 as we correctly classify each point. However, correctly classifying every single training point is usually not a good indicator because that means the model will not be able to generalize to the testing data! This model correclty classifies every single training point because we did not limit the maximum depth and during training, we give the model the answers as well as the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_log = pd.DataFrame(model.feature_importances_, index = X_train.columns.tolist(), \n",
    "                            columns = ['Importance'])\n",
    "features_log = features_log.sort_values(by='Importance', ascending=True)\n",
    "\n",
    "features_log.plot(kind='barh', figsize=(12,9), color = 'blue')\n",
    "plt.xlabel('Feature importance')\n",
    "plt.title('Feature importance for the logistic regression model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The confusion Matrix\n",
    "\n",
    "> Don't let the name confuse you!\n",
    "\n",
    "* The confusion matrix enables to have an overview of the performance of a classification predictive model, as it indicates the number of events which were predicted correctly - either the 'LOW' or 'HIGH' concentrations (i.e., 'true positives' and 'true negatives') - and the number of events which were not predicted accurately (i.e., 'false positives' and 'false negatives').\n",
    "\n",
    "\n",
    "\n",
    "![](images/confusion_matrix_v2.png)\n",
    "Source: McKinsey\n",
    "\n",
    "* **NB**: TP = True Positives, FP = False Positives, FN = False Negatives, FP = False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the confusion matrix of the logistic regression\n",
    "rf_cfn = confusion_matrix(y_test, y_pred_bin)\n",
    "rf_tp, rf_fp, rf_fn, rf_tn = confusion_matrix(y_test, y_pred_bin).ravel()\n",
    "# plot_confusion_matrix(logit_cfn, classes = ['Low', 'High'])\n",
    "\n",
    "class_names = ['no disease', 'disease']\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(rf_cfn, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(rf_cfn, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> How good are our models? \n",
    "\n",
    "###### It depends\\*... what metric we are looking at!\n",
    "\n",
    "\\*this verb will often be used in machine learning, as there are many tradeoffs, depending on the business needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "\n",
    "Another common metric is the Area Under the Curve, or AUC. This is a convenient way to capture the performance of a model in a single number, although it's not without certain issues. As a rule of thumb, an AUC can be classed as follows,\n",
    "\n",
    "* 0.90 - 1.00 = **excellent**\n",
    "* 0.80 - 0.90 = **good**\n",
    "* 0.70 - 0.80 = **fair**\n",
    "* 0.60 - 0.70 = **poor**\n",
    "* 0.50 - 0.60 = **fail**\n",
    "\n",
    "Let's see what the above ROC gives us,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_quant)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr)\n",
    "ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for heart disease classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auc(fpr, tpr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
